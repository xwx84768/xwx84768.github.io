---
layout: home
permalink: /
title: "Xiangwen Wang"
author_profile: true
---

Hi! I'm **Xiangwen Wang (王香雯)**, a first-year MSCS student at the University of Illinois Urbana–Champaign (UIUC). My research interests lie in **AI alignment**, **preference learning**, and **post-training for large language models**, with a focus on the safety and reliability of complex **compound AI systems**.

Previously, I spent a summer as a research intern at **Stanford University** and was a visiting student at **UC Berkeley**. I have also collaborated with research groups at **UNC Chapel Hill** and **USTC** on LLM safety, adversarial robustness, and trustworthy machine learning.

My long-term goal is to build AI systems that are **safe, robust, and value-aligned**, even when deployed as multi-component or multi-agent systems.

### Research Interests

- **AI Alignment & Preference Learning**  
  System-level alignment, Direct Preference Optimization (DPO), alignment of compound systems

- **LLM Safety & Reliability**  
  Jailbreak and trojan attacks, RL-based red-teaming, post-training safety

- **Adversarial Robustness**  
  Detection and characterization of adversarial examples, generalization to unseen attacks

### Selected News

- **NeurIPS 2025** – *Aligning Compound AI Systems via System-level DPO* accepted.  
- **ICME 2025** – *Adversarial Examples Detection Based on Adversarial Attack Sensitivity* accepted.  
- **ACL 2024 (Oral)** – *Reinforcement Learning-Driven LLM Agent for Automated Attacks on LLMs* accepted at the Privacy in NLP workshop.

### Contact

- Email: `xw120@illinois.edu`  
- GitHub: [xwx84768](https://github.com/xwx84768)
